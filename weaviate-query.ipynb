{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Notes:**\n",
    "Give the journey through the queries to get to the answer describing how we got there using weaviate queries\n",
    "\n",
    "to tell a story around the application\n",
    "\n",
    "Not the features \n",
    "\n",
    "this is how it can be used and its beneficial \n",
    "\n",
    "\n",
    "GenAi - Make it easier\n",
    "\n",
    "\n",
    "Write what the story we want to do\n",
    "\n",
    "## Get answers to USCG Auxiliary questions from authoritative sources.\n",
    "\n",
    "ASK uses Artificial Intelligence (AI) to search over 251 Coast Guard Auxiliary references for answers. This is a working prototype for evaluation. Not an official USCG Auxiliary service. Learn more here.\n",
    "\n",
    "ASK answers questions such as:\n",
    "\n",
    "- What are the requirements to run for FC?\n",
    "- How do I stay current in boat crew?\n",
    "- Â¿En que ocasiones es necesario un saludo militar?\n",
    "\n",
    "\n",
    "Types of documents:  PDF manuals for Coast Gaurd Intelligence\n",
    "\n",
    "\n",
    "The journey to better question/answer response\n",
    "1. Keyword search\n",
    "2. Semantic gets closer\n",
    "3. Leverage GenAi \n",
    "\n",
    "\n",
    "\n",
    "### Example Query Types\n",
    "\n",
    "#### Queries No Filters ####\n",
    "- Keyword search on full document collection\n",
    "- Semantic Search on full document collection\n",
    "- Generative on Full document Collection\n",
    "- Generative per result\n",
    "\n",
    "#### Queries With Filters ####\n",
    "- Time Range\n",
    "- Source\n",
    "- Organization\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import re\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from dateutil import parser\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://fksy6wnuqfscrfox3d2c0w.c0.us-east1.gcp.weaviate.cloud\"\n",
    "api_key = \"kpL3TO3LlGlD8D08nmDvLwhnQknZrvu64HO8\"\n",
    "\n",
    "client = weaviate.connect_to_wcs(\n",
    "    cluster_url=url,\n",
    "    auth_credentials=weaviate.auth.AuthApiKey(api_key),\n",
    "    headers={\n",
    "        \"X-OpenAI-Api-Key\": os.environ.get(\"OPENAI_API_KEY\")\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and see if Weviate is Healthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.is_live()\n",
    "import json\n",
    "\n",
    "metainfo = client.get_meta()\n",
    "print(json.dumps(metainfo, indent=2))  # Print the meta information in a readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_FULL_DOCUMENTS = \"PDF_document\"\n",
    "COLLECTION_DOCUMENT_PAGES = \"PDF_document_page\"\n",
    "\n",
    "QUERY = \"What are the requirements to run for FC?\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Search (Near Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes.query as wq\n",
    "import json\n",
    "from weaviate.classes.query import QueryReference\n",
    "\n",
    "\n",
    "# Get the collection\n",
    "pdf_pages_collection = client.collections.get(COLLECTION_DOCUMENT_PAGES)\n",
    "\n",
    "# Perform query to the \n",
    "\n",
    "response = pdf_pages_collection.query.near_text(\n",
    "    query=QUERY, limit=5, \n",
    "    return_metadata=wq.MetadataQuery(distance=True),\n",
    "    return_references=[\n",
    "        QueryReference(\n",
    "            link_on=\"hasPdfDocument\",\n",
    "            return_properties=[\"organization\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# return_properties=[\"organization, curator, source, effective_date\"]\n",
    "\n",
    "# results = weaviate_response_to_dict(response)\n",
    "# print(results)\n",
    "print(response)\n",
    "# # Inspect the response\n",
    "for o in response.objects:\n",
    "    print(json.dumps(o.properties, indent=2))  # Print the object properties (metadata and propert\n",
    "    print(\"-------------------Response Metadata-------------------\")\n",
    "    print(o.metadata)\n",
    "    for obj in o.references['hasPdfDocument'].objects:\n",
    "        print(obj.properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Search with Generative Output across all returned documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def retrieval_context_excel_to_dict(file_path):\n",
    "    ''' Read Excel file into a dictionary of worksheets. \n",
    "    Each worksheet is its own dictionary. Column 1 is \n",
    "    the key. Column 2 is the values'''\n",
    "\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    dict = {}\n",
    "\n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "        if df.shape[1] >= 2:\n",
    "            dict[sheet_name] = pd.Series(\n",
    "                df.iloc[:, 1].values, index=df.iloc[:, 0]).to_dict()\n",
    "        else:\n",
    "            print(f\"The sheet '{sheet_name}' does not have enough columns.\")\n",
    "    return dict\n",
    "\n",
    "retrieval_context_dict = retrieval_context_excel_to_dict('utils/retrieval_context.xlsx')\n",
    "acronyms_dict = retrieval_context_dict.get(\"acronyms\", None)\n",
    "acronyms_json = json.dumps(acronyms_dict, indent=4)\n",
    "terms_dict = retrieval_context_dict.get(\"terms\", None)\n",
    "terms_json = json.dumps(terms_dict, indent=4)\n",
    "\n",
    "user_message = f\"User question: {QUERY}```acronyms_json: {acronyms_json}\\n\\nterms_json: {terms_json}```\"\n",
    "\n",
    "query_prompt = f\"\"\"\n",
    "Your task is to modify the user's question based on two lists: 'acronym_json' and 'terms_json'. Each list contains terms and their associated additional information. Follow these instructions:\n",
    "\n",
    "- Review the user's question and identify if any acronyms from 'acronym_json' or phrases in 'terms_json' appear in it.\n",
    "- If an acronym from 'acronym_json' replace the term with the associated additional information.\n",
    "- If a phrase from 'terms_json' appears in the question, append its associated additional information to the end of the question.\n",
    "- Do not remove or alter any other part of the original question.\n",
    "- Do not provide an answer to the question.\n",
    "- If no terms from either list are found in the question, leave the question as is.\n",
    "\n",
    "Example:\n",
    "- Question: How do I get a VE certification?\n",
    "- Your response: How do I get a vessel examiner certification? Certification includes information about initial qualification.\n",
    "\n",
    "- Question: What are the requirements for pilot training?\n",
    "- Your response: What are the requirements for pilot training? Pilot is a position in the aviation program.\n",
    "\n",
    "    - Question: What is required to stay current in the Auxiliary?\n",
    "- Your response: What is required to stay current in the Auxiliary? To be in the Auxiliary, members are required to maintain the Core Training (AUXCT), undego an annual uniform inspection, and pay annual dues.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Instructions RAG Prompt\n",
    "\n",
    "This is the second step as part of the QnA system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = f\"\"\"\n",
    "    Use the following pieces of context to answer the users question. \n",
    "    \n",
    "    INCLUDES ALL OF THE DETAILS IN YOUR RESPONSE, INDLUDING REQUIREMENTS AND REGULATIONS. \n",
    "    \n",
    "    National Workshops are required for boat crew, aviation, and telecommunications when then are offered and you should mention this in questions about those programs. \n",
    "    Include Auxiliary Core Training (AUXCT) in your response for any question regarding certifications or officer positions.\n",
    "    \n",
    "    If you don't know the answer, just say I don't know, don't try to make up an answer. \n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated Response\n",
    "\n",
    "A single prompt that uses all the results returned from weaviate to generate 1 response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes.query as wq\n",
    "import json\n",
    "from weaviate.classes.query import QueryReference\n",
    "import textwrap\n",
    "\n",
    "\n",
    "\n",
    "# Get the collection\n",
    "pdf_pages_collection = client.collections.get(COLLECTION_DOCUMENT_PAGES)\n",
    "\n",
    "# Perform query to the\n",
    "# increase response window \n",
    "\n",
    "response = pdf_pages_collection.generate.near_text(\n",
    "    query=QUERY, \n",
    "    limit=6,\n",
    "    return_metadata=wq.MetadataQuery(distance=True),\n",
    "    return_references=[\n",
    "        QueryReference(\n",
    "            link_on=\"hasPdfDocument\",\n",
    "            return_properties=[\"organization\"]\n",
    "        ),\n",
    "    ],\n",
    "    grouped_task=instruction_prompt,\n",
    "    grouped_properties=[\"content\"]\n",
    "\n",
    ")\n",
    "\n",
    "# return_properties=[\"organization, curator, source, effective_date\"]\n",
    "\n",
    "\n",
    "print(f\"\"\"\n",
    "-----------------------------Generated Response------------------------------------------\n",
    "{textwrap.fill(response.generated, width=80)}\n",
    "-----------------------------End Generation-----------------------------\\n\n",
    "\"\"\")\n",
    "\n",
    "\n",
    " # Inspect the response\n",
    "for o in response.objects:\n",
    "    print(json.dumps(o.properties, indent=2))  # Print the object properties (metadata and propert\n",
    "    print(\"-------------------Document  Metadata-------------------\")\n",
    "    print(o.metadata)\n",
    "    for obj in o.references['hasPdfDocument'].objects:\n",
    "        print(obj.properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Response\n",
    "\n",
    "A single prompt that will be applied to each individual document returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate.classes.query as wq\n",
    "import json\n",
    "from weaviate.classes.query import QueryReference\n",
    "import textwrap\n",
    "\n",
    "\n",
    "\n",
    "# Get the collection\n",
    "pdf_pages_collection = client.collections.get(COLLECTION_DOCUMENT_PAGES)\n",
    "prompt = \"Summarize in 10 words\"\n",
    "\n",
    "# Perform query to the \n",
    "\n",
    "response = pdf_pages_collection.generate.near_text(\n",
    "    query=QUERY, \n",
    "    limit=5,\n",
    "    return_metadata=wq.MetadataQuery(distance=True),\n",
    "    return_references=[\n",
    "        QueryReference(\n",
    "            link_on=\"hasPdfDocument\",\n",
    "            return_properties=[\"organization\"]\n",
    "        ),\n",
    "    ],\n",
    "    single_prompt=prompt\n",
    ")\n",
    "\n",
    "# return_properties=[\"organization, curator, source, effective_date\"]\n",
    "\n",
    "\n",
    "\n",
    "# # Inspect the response\n",
    "for o in response.objects:\n",
    "    print(json.dumps(o.properties, indent=2))  # Print the object properties (metadata and propert\n",
    "    # -----------------------------Generated Response------------------------------------------\n",
    "    # {textwrap.fill(response.generated, width=80)}\n",
    "    print(\"-------------------Response Metadata-------------------\")\n",
    "    print(o.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
